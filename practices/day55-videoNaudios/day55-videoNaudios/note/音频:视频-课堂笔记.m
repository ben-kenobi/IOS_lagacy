//#pragma mark - 一. 音频
//
//#pragma mark 1. 音效 (理解)
//一. 音效文件的简单使用
///**
// 1. 导入框架
// 2. 创建系统音效
// 3. 播放音效
// */
//1. 获取URL地址
//2. 创建SystemSoundID
//3. 创建音效: AudioServicesCreateSystemSoundID
//4. 4. 播放音效
//    4.1 不带震动的播放: AudioServicesPlaySystemSound
//    4.2 带震动的播放 --> 只能真机才有效果:AudioServicesPlayAlertSound
//5. 移除音效文件:AudioServicesDisposeSystemSoundID
//
//注意点: 如果要注册成系统声音服务, 长度一定不能大于30秒.
//
//二. 工具类的抽取
//此时, SoundID会重复创建
//一个URL地址, 将来对应的是一个soundID, 那么就可以用字典来记录
//1. 用一个可变字典来做缓存, 记录URL地址和SoundID的值
//2. 在initialize方法中进行初始化字典:类的实例对象被创建的时候会调用
//3. 缓存方法
//    3.1 先判断缓存字典中, 是否有URL对应的soundID. 如果soundID存在, 直接播放, 如果soundID为0, 则需要创建, 并记录
//    3.2 记录URL对应的soundID
//
//三. 音效文件的内存清除
//1. 遍历字典
//2. 缓存字典清空
//注意: 全局的释放, 在AppDelegate. 局部的释放, 在当前控制器
//
//#pragma mark 2. 音乐 (掌握)
///**
// 1. 导入AVFoundation框架
// 2. 创建音乐播放器
// 3. 根据需求进行 播放/暂停/停止等功能的实现
// */
//1. 获取URL地址
//2. 创建Error对象 --> 可选
//3. 创建音乐播放器
//4. 根据需求, 进行方法的调用. 注意如果要停止, 需要手动将时间归零
//
//
//#pragma mark 3. 录音 (理解)
///**
// 1. 导入AVFoundation框架
// 2. 创建录音器
// 3. 根据需求进行 播放/暂停/停止等功能的实现
// */
//一. 录音的实现
//1. 这里的URL地址, 指的是将来要保存的地址
//2. 获取URL地址 调用此方法, 会自动拼接file://
//3. 录音设置 --> 如果不传, 则默认按照最高配置类录音
//4. 创建录音器
//5. 根据需求进行方法的调用
//
//细节
//1. 如果路径不变, 再次录制, 会覆盖源文件
//2. 暂停时, 文件不会发生改变 ---> 文件没有被生产
//3. 当停止的时候, 文件大小才会改变 --> 文件从内存生产了文件导出在磁盘中
//
//二. 自动停止录音的功能实现
//1. 打开分贝检测功能
//2. 录音开始检测 --> 计时器循环调用, 来不断的获取当前的分贝值
//    2.1 创建计时器
//    2.2 如果计时器暂停就启用
//3. 检测分贝的方法
//    3.1 更新分贝信息
//    3.2 获取分贝信息 --> 如果是IOS设备, 传0
//    3.3  2S停止的处理
//        3.3.1 定义全局的count来记录次数
//        3.3.2 如果声音小于某个值, 就自增一次
//        3.3.3 当count超过120时, 就可以将count归零, 然后调用停止方法
//
//三. 真机录音的注意点
//1 创建一个AVAudioSession对象
//2 设置分类信息
//
//#pragma mark - 二. 视频
//
//#pragma mark 1. 视频播放 (掌握)
//#import <MediaPlayer/MediaPlayer.h>
//一. 带View的播放器
//1. 获取URL地址
//2. 创建视频播放视图控制器
//3. 模态视图展示 --> 不应该在视图没有出现之前, 发送模态行为
//
//二. 不带view的播放器
//1. 获取URL地址
//2. 创建视频播放控制器 -->  需要强引用, 设置frame, 添加视图上, 手动播放
//3. 设置位置
//4. 添加view
//5. 开始播放 --> 准备播放 --> 可以不写, 自动会调用此方法
//6. 控制风格
//
//三. 不带View的视图移除 --> 监听播放完成
//1. 注册通知, 监听播放完成: MPMoviePlayerPlaybackDidFinishNotification
//2. 通知绑定的方法
//    2.1 获取通知的值 --> 播放完成的状态值
//    2.2 根据不同的状态值, 来区分不同的场景
//    2.3 不管是播放完成, 还是失败, 都需要移除视图
//
//四. 连续播放视频
//1. 注册通知
//2. 在通知的方法中进行判断
//    2.1 将来应该根据需求来播放, 如果没有URL可以播放的时候, 那么应该移除视图
//    2.2 否则, 就更换URL地址, 然后调用play方法
//
//五. iOS9AVKit
//#import <AVKit/AVKit.h>
//#import <AVFoundation/AVFoundation.h>
//1. 获取URL地址
//2. 创建AV播放器 AVPlayerViewController --> 真正播放的, 是AVPlayer
//3. 设置AVPlayer --> 此处需要导入AVFoundation
//4. 开始播放
//5. 模态视图呈现
//5. 自定义位置
//6. 添加view上
//
//AVPlayer是从iOS4就有的
//在iOS中实现视频播放2中方式
//1. 使用系统封装好的类: MP开头的类  --> 微信, QQ
//2. AVPlayer, 功能强大, 但是需要自定义 --> 优酷, 斗鱼
//
//#pragma mark 2. 视频截图 (理解)
//1. 获取URL地址
//2. 获取资源
//3. 创建图像生成类
//4. 调用generate方法生成图像
//    4.1 CMTime --> 专门用于表示影片时间的值
//    //第一个值, 代表着要获取的第几帧, 第二值, 代表着影片一秒有几帧
//    //第一个值, 是根据后面的值来换算的
//    4.2 CMTime 需要转换成 NSValue 是专门用户包装结构体的
//    4.3 主队列中更新图片
//
//#pragma mark 3. 视频录制 (理解)
//1. 按照选取图像的方法进行填写代码
//2. 增加 设置媒体类型 mediaTypes (NSString *)kUTTypeMovie --> 需要MobileCoreServices框架
//3. 在代理方法中
//    3.1  获取类型
//    3.2. 判断如果是public.movie则可以播放视频
//    3.3. 保存视频 --> 1. sourceType = camera  2. mediaType = kUTTypeMovie
//        ALAssetsLibrary  进行保存
//
//
//#pragma mark 4. 视频压缩 (了解)
//
//
//
//
//
//
//
//
//
//
//
//
//
//
//
//
//
//// 音Ω频采样率
//setting[AVSampleRateKey] = @(600.0);
//// 音频通道数
//setting[AVNumberOfChannelsKey] = @(1);
//// 线性音频的位深度
//setting[AVLinearPCMBitDepthKey] = @(8);